{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import PIL.Image as Image\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from MathExpressionDataset import MEdataset\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 109 #108 LaTeX symbols + the background/nothing\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = r'C:\\Users\\maxwe\\Desktop\\My Documents\\MathExprSolverMx\\MathExprSolverMx\\AidaCalculusHandWrittenMathDataset\\archive\\train'\n",
    "testDir = r'C:\\Users\\maxwe\\Desktop\\My Documents\\MathExprSolverMx\\MathExprSolverMx\\AidaCalculusHandWrittenMathDataset\\archive\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset = MEdataset(trainDir, get_transform(train=True))\n",
    "dataset_test = MEdataset(testDir, get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indicesTrain = torch.randperm(len(dataset)).tolist()\n",
    "indicesTest = torch.randperm(len(dataset_test)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indicesTrain[:])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indicesTest[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=109, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=436, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to the right device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/500]  eta: 0:34:03  lr: 0.000015  loss: 7.1823 (7.1823)  loss_classifier: 4.6797 (4.6797)  loss_box_reg: 0.9286 (0.9286)  loss_objectness: 1.4138 (1.4138)  loss_rpn_box_reg: 0.1603 (0.1603)  time: 4.0879  data: 2.4531  max mem: 1911\n",
      "Epoch: [0]  [ 10/500]  eta: 0:06:12  lr: 0.000115  loss: 7.1823 (7.3501)  loss_classifier: 4.5375 (4.4591)  loss_box_reg: 0.9360 (0.9436)  loss_objectness: 1.4138 (1.4139)  loss_rpn_box_reg: 0.3599 (0.5335)  time: 0.7610  data: 0.2247  max mem: 2835\n",
      "Epoch: [0]  [ 20/500]  eta: 0:04:55  lr: 0.000215  loss: 5.1327 (5.8713)  loss_classifier: 3.9219 (3.7098)  loss_box_reg: 0.9349 (0.9153)  loss_objectness: 0.1264 (0.7840)  loss_rpn_box_reg: 0.3490 (0.4622)  time: 0.4429  data: 0.0022  max mem: 2835\n",
      "Epoch: [0]  [ 30/500]  eta: 0:04:23  lr: 0.000315  loss: 3.4746 (5.0723)  loss_classifier: 1.8772 (3.1038)  loss_box_reg: 0.9200 (0.9263)  loss_objectness: 0.0865 (0.5611)  loss_rpn_box_reg: 0.4093 (0.4811)  time: 0.4488  data: 0.0013  max mem: 2846\n",
      "Epoch: [0]  [ 40/500]  eta: 0:04:01  lr: 0.000415  loss: 3.2072 (4.5878)  loss_classifier: 1.6785 (2.7447)  loss_box_reg: 0.9172 (0.9169)  loss_objectness: 0.0769 (0.4458)  loss_rpn_box_reg: 0.5126 (0.4804)  time: 0.4271  data: 0.0013  max mem: 2846\n",
      "Epoch: [0]  [ 50/500]  eta: 0:03:45  lr: 0.000516  loss: 3.0729 (4.2755)  loss_classifier: 1.5836 (2.5130)  loss_box_reg: 0.8902 (0.9143)  loss_objectness: 0.0769 (0.3730)  loss_rpn_box_reg: 0.4515 (0.4753)  time: 0.4084  data: 0.0017  max mem: 2846\n",
      "Epoch: [0]  [ 60/500]  eta: 0:03:31  lr: 0.000616  loss: 2.9692 (4.0507)  loss_classifier: 1.5438 (2.3488)  loss_box_reg: 0.8788 (0.9061)  loss_objectness: 0.0581 (0.3214)  loss_rpn_box_reg: 0.4970 (0.4743)  time: 0.3915  data: 0.0016  max mem: 2846\n",
      "Epoch: [0]  [ 70/500]  eta: 0:03:19  lr: 0.000716  loss: 2.8441 (3.8889)  loss_classifier: 1.4772 (2.2246)  loss_box_reg: 0.8766 (0.9045)  loss_objectness: 0.0487 (0.2837)  loss_rpn_box_reg: 0.4187 (0.4762)  time: 0.3714  data: 0.0013  max mem: 2846\n",
      "Epoch: [0]  [ 80/500]  eta: 0:03:12  lr: 0.000816  loss: 2.6620 (3.7414)  loss_classifier: 1.4352 (2.1236)  loss_box_reg: 0.8766 (0.9003)  loss_objectness: 0.0497 (0.2567)  loss_rpn_box_reg: 0.2464 (0.4607)  time: 0.3916  data: 0.0009  max mem: 2846\n",
      "Epoch: [0]  [ 90/500]  eta: 0:03:06  lr: 0.000916  loss: 2.5958 (3.6317)  loss_classifier: 1.3746 (2.0409)  loss_box_reg: 0.8566 (0.8942)  loss_objectness: 0.0555 (0.2357)  loss_rpn_box_reg: 0.2492 (0.4611)  time: 0.4215  data: 0.0019  max mem: 2846\n",
      "Epoch: [0]  [100/500]  eta: 0:02:59  lr: 0.001016  loss: 2.6495 (3.5312)  loss_classifier: 1.3421 (1.9686)  loss_box_reg: 0.8493 (0.8901)  loss_objectness: 0.0545 (0.2186)  loss_rpn_box_reg: 0.3667 (0.4538)  time: 0.4073  data: 0.0016  max mem: 2846\n",
      "Epoch: [0]  [110/500]  eta: 0:02:54  lr: 0.001116  loss: 2.5571 (3.4406)  loss_classifier: 1.2711 (1.9057)  loss_box_reg: 0.8264 (0.8863)  loss_objectness: 0.0509 (0.2036)  loss_rpn_box_reg: 0.3667 (0.4449)  time: 0.4215  data: 0.0010  max mem: 2846\n",
      "Epoch: [0]  [120/500]  eta: 0:02:50  lr: 0.001216  loss: 2.5312 (3.3683)  loss_classifier: 1.2429 (1.8485)  loss_box_reg: 0.8392 (0.8823)  loss_objectness: 0.0434 (0.1902)  loss_rpn_box_reg: 0.3699 (0.4474)  time: 0.4501  data: 0.0008  max mem: 2846\n",
      "Epoch: [0]  [130/500]  eta: 0:02:44  lr: 0.001316  loss: 2.4279 (3.2949)  loss_classifier: 1.1823 (1.7952)  loss_box_reg: 0.8189 (0.8760)  loss_objectness: 0.0425 (0.1795)  loss_rpn_box_reg: 0.4092 (0.4442)  time: 0.4151  data: 0.0005  max mem: 2846\n",
      "Epoch: [0]  [140/500]  eta: 0:02:37  lr: 0.001416  loss: 2.4009 (3.2416)  loss_classifier: 1.1362 (1.7458)  loss_box_reg: 0.7825 (0.8691)  loss_objectness: 0.0438 (0.1701)  loss_rpn_box_reg: 0.4262 (0.4566)  time: 0.3784  data: 0.0011  max mem: 2846\n",
      "Epoch: [0]  [150/500]  eta: 0:02:32  lr: 0.001517  loss: 2.3875 (3.1853)  loss_classifier: 1.0801 (1.6990)  loss_box_reg: 0.7617 (0.8621)  loss_objectness: 0.0469 (0.1621)  loss_rpn_box_reg: 0.5200 (0.4621)  time: 0.3927  data: 0.0025  max mem: 2846\n",
      "Epoch: [0]  [160/500]  eta: 0:02:28  lr: 0.001617  loss: 2.2977 (3.1273)  loss_classifier: 1.0180 (1.6580)  loss_box_reg: 0.7549 (0.8549)  loss_objectness: 0.0327 (0.1545)  loss_rpn_box_reg: 0.4655 (0.4600)  time: 0.4325  data: 0.0028  max mem: 2846\n",
      "Epoch: [0]  [170/500]  eta: 0:02:24  lr: 0.001717  loss: 2.0829 (3.0647)  loss_classifier: 0.9959 (1.6191)  loss_box_reg: 0.7194 (0.8458)  loss_objectness: 0.0388 (0.1483)  loss_rpn_box_reg: 0.3097 (0.4515)  time: 0.4375  data: 0.0022  max mem: 2846\n",
      "Epoch: [0]  [180/500]  eta: 0:02:19  lr: 0.001817  loss: 2.0397 (3.0081)  loss_classifier: 0.9542 (1.5817)  loss_box_reg: 0.6901 (0.8377)  loss_objectness: 0.0410 (0.1431)  loss_rpn_box_reg: 0.2636 (0.4456)  time: 0.4290  data: 0.0026  max mem: 2846\n",
      "Epoch: [0]  [190/500]  eta: 0:02:14  lr: 0.001917  loss: 1.9911 (2.9552)  loss_classifier: 0.9125 (1.5466)  loss_box_reg: 0.6827 (0.8288)  loss_objectness: 0.0336 (0.1375)  loss_rpn_box_reg: 0.3618 (0.4423)  time: 0.4203  data: 0.0036  max mem: 2846\n",
      "Epoch: [0]  [200/500]  eta: 0:02:10  lr: 0.002017  loss: 1.9911 (2.9085)  loss_classifier: 0.8893 (1.5126)  loss_box_reg: 0.6806 (0.8198)  loss_objectness: 0.0403 (0.1340)  loss_rpn_box_reg: 0.3695 (0.4421)  time: 0.4085  data: 0.0026  max mem: 2846\n",
      "Epoch: [0]  [210/500]  eta: 0:02:05  lr: 0.002117  loss: 2.0215 (2.8663)  loss_classifier: 0.8500 (1.4818)  loss_box_reg: 0.6088 (0.8095)  loss_objectness: 0.0513 (0.1316)  loss_rpn_box_reg: 0.4366 (0.4434)  time: 0.4074  data: 0.0016  max mem: 2846\n",
      "Epoch: [0]  [220/500]  eta: 0:02:00  lr: 0.002217  loss: 2.0229 (2.8277)  loss_classifier: 0.8364 (1.4521)  loss_box_reg: 0.6009 (0.8003)  loss_objectness: 0.0646 (0.1284)  loss_rpn_box_reg: 0.5175 (0.4469)  time: 0.3967  data: 0.0016  max mem: 2846\n",
      "Epoch: [0]  [230/500]  eta: 0:01:56  lr: 0.002317  loss: 1.8548 (2.7857)  loss_classifier: 0.7920 (1.4229)  loss_box_reg: 0.5848 (0.7906)  loss_objectness: 0.0501 (0.1250)  loss_rpn_box_reg: 0.4179 (0.4473)  time: 0.4057  data: 0.0022  max mem: 2846\n",
      "Epoch: [0]  [240/500]  eta: 0:01:52  lr: 0.002417  loss: 1.8090 (2.7434)  loss_classifier: 0.7711 (1.3959)  loss_box_reg: 0.5693 (0.7813)  loss_objectness: 0.0394 (0.1212)  loss_rpn_box_reg: 0.4025 (0.4450)  time: 0.4338  data: 0.0027  max mem: 2847\n",
      "Epoch: [0]  [250/500]  eta: 0:01:47  lr: 0.002518  loss: 1.7091 (2.7071)  loss_classifier: 0.7672 (1.3714)  loss_box_reg: 0.5693 (0.7730)  loss_objectness: 0.0343 (0.1183)  loss_rpn_box_reg: 0.4091 (0.4443)  time: 0.4136  data: 0.0015  max mem: 2847\n",
      "Epoch: [0]  [260/500]  eta: 0:01:42  lr: 0.002618  loss: 1.6711 (2.6676)  loss_classifier: 0.7449 (1.3473)  loss_box_reg: 0.5405 (0.7636)  loss_objectness: 0.0457 (0.1155)  loss_rpn_box_reg: 0.3473 (0.4413)  time: 0.3885  data: 0.0011  max mem: 2847\n"
     ]
    }
   ],
   "source": [
    "# let's train it for 10 epochs\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "savePath = os.path.join(os.getcwd(), 'model1.pt')\n",
    "torch.save(model.state_dict(), savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
