{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import PIL.Image as Image\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "from MathExpressionDataset import MEdataset\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 109 #108 LaTeX symbols + the background/nothing\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDir = r'C:\\Users\\maxwe\\Desktop\\My Documents\\MathExprSolverMx\\MathExprSolverMx\\AidaCalculusHandWrittenMathDataset\\archive\\train'\n",
    "testDir = r'C:\\Users\\maxwe\\Desktop\\My Documents\\MathExprSolverMx\\MathExprSolverMx\\AidaCalculusHandWrittenMathDataset\\archive\\test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on the GPU or on the CPU, if a GPU is not available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset = MEdataset(trainDir, get_transform(train=True))\n",
    "dataset_test = MEdataset(testDir, get_transform(train=False))\n",
    "\n",
    "# split the dataset in train and test set\n",
    "indicesTrain = torch.randperm(len(dataset)).tolist()\n",
    "indicesTest = torch.randperm(len(dataset_test)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indicesTrain[:])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indicesTest[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=109, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=436, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move model to the right device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [    0/54500]  eta: 2 days, 19:10:44  lr: 0.000010  loss: 8.9632 (8.9632)  loss_classifier: 4.8027 (4.8027)  loss_box_reg: 0.8858 (0.8858)  loss_objectness: 2.9559 (2.9559)  loss_rpn_box_reg: 0.3188 (0.3188)  time: 4.4375  data: 2.7510  max mem: 2191\n",
      "Epoch: [0]  [   10/54500]  eta: 12:05:54  lr: 0.000060  loss: 8.9632 (8.7948)  loss_classifier: 4.6958 (4.7006)  loss_box_reg: 0.9224 (0.8675)  loss_objectness: 2.7816 (2.5493)  loss_rpn_box_reg: 0.5870 (0.6773)  time: 0.7993  data: 0.2518  max mem: 2833\n",
      "Epoch: [0]  [   20/54500]  eta: 9:22:42  lr: 0.000110  loss: 6.2447 (7.3620)  loss_classifier: 4.3924 (4.3649)  loss_box_reg: 0.9190 (0.8487)  loss_objectness: 0.2765 (1.4981)  loss_rpn_box_reg: 0.5775 (0.6503)  time: 0.4288  data: 0.0019  max mem: 3203\n",
      "Epoch: [0]  [   30/54500]  eta: 8:54:44  lr: 0.000160  loss: 4.8855 (6.3033)  loss_classifier: 3.1837 (3.7383)  loss_box_reg: 0.8848 (0.8148)  loss_objectness: 0.1026 (1.1449)  loss_rpn_box_reg: 0.4561 (0.6054)  time: 0.4734  data: 0.0018  max mem: 3219\n",
      "Epoch: [0]  [   40/54500]  eta: 8:14:31  lr: 0.000210  loss: 3.6103 (5.5576)  loss_classifier: 1.7910 (3.2224)  loss_box_reg: 0.8881 (0.8250)  loss_objectness: 0.1081 (0.8964)  loss_rpn_box_reg: 0.4771 (0.6138)  time: 0.4662  data: 0.0017  max mem: 3219\n",
      "Epoch: [0]  [   50/54500]  eta: 8:03:38  lr: 0.000260  loss: 3.1242 (5.0524)  loss_classifier: 1.6237 (2.8828)  loss_box_reg: 0.8816 (0.8220)  loss_objectness: 0.1013 (0.7432)  loss_rpn_box_reg: 0.5545 (0.6044)  time: 0.4460  data: 0.0018  max mem: 3219\n",
      "Epoch: [0]  [   60/54500]  eta: 7:44:49  lr: 0.000310  loss: 2.8674 (4.7095)  loss_classifier: 1.5698 (2.6672)  loss_box_reg: 0.8981 (0.8366)  loss_objectness: 0.0700 (0.6335)  loss_rpn_box_reg: 0.3265 (0.5722)  time: 0.4456  data: 0.0021  max mem: 3219\n",
      "Epoch: [0]  [   70/54500]  eta: 7:36:41  lr: 0.000360  loss: 2.8342 (4.4545)  loss_classifier: 1.5517 (2.5009)  loss_box_reg: 0.8984 (0.8391)  loss_objectness: 0.0736 (0.5560)  loss_rpn_box_reg: 0.3164 (0.5585)  time: 0.4282  data: 0.0020  max mem: 3219\n",
      "Epoch: [0]  [   80/54500]  eta: 7:39:54  lr: 0.000410  loss: 2.8512 (4.2286)  loss_classifier: 1.5045 (2.3527)  loss_box_reg: 0.8898 (0.8294)  loss_objectness: 0.0620 (0.4956)  loss_rpn_box_reg: 0.4709 (0.5510)  time: 0.4911  data: 0.0017  max mem: 3529\n",
      "Epoch: [0]  [   90/54500]  eta: 7:40:03  lr: 0.000460  loss: 2.8007 (4.0588)  loss_classifier: 1.4717 (2.2410)  loss_box_reg: 0.8573 (0.8252)  loss_objectness: 0.0474 (0.4469)  loss_rpn_box_reg: 0.4406 (0.5457)  time: 0.5212  data: 0.0016  max mem: 3529\n",
      "Epoch: [0]  [  100/54500]  eta: 7:42:26  lr: 0.000509  loss: 2.7714 (3.9116)  loss_classifier: 1.4397 (2.1437)  loss_box_reg: 0.8573 (0.8163)  loss_objectness: 0.0668 (0.4107)  loss_rpn_box_reg: 0.3840 (0.5410)  time: 0.5221  data: 0.0021  max mem: 3529\n",
      "Epoch: [0]  [  110/54500]  eta: 7:39:17  lr: 0.000559  loss: 2.7471 (3.8205)  loss_classifier: 1.4305 (2.0807)  loss_box_reg: 0.8632 (0.8225)  loss_objectness: 0.0749 (0.3795)  loss_rpn_box_reg: 0.3989 (0.5378)  time: 0.5037  data: 0.0022  max mem: 3529\n",
      "Epoch: [0]  [  120/54500]  eta: 7:42:38  lr: 0.000609  loss: 2.7024 (3.6937)  loss_classifier: 1.4124 (2.0070)  loss_box_reg: 0.8762 (0.8153)  loss_objectness: 0.0556 (0.3525)  loss_rpn_box_reg: 0.3690 (0.5190)  time: 0.5125  data: 0.0018  max mem: 3529\n",
      "Epoch: [0]  [  130/54500]  eta: 7:43:46  lr: 0.000659  loss: 2.6008 (3.5868)  loss_classifier: 1.3566 (1.9434)  loss_box_reg: 0.8424 (0.8093)  loss_objectness: 0.0518 (0.3308)  loss_rpn_box_reg: 0.2434 (0.5033)  time: 0.5403  data: 0.0018  max mem: 3529\n",
      "Epoch: [0]  [  140/54500]  eta: 7:46:05  lr: 0.000709  loss: 2.5439 (3.4867)  loss_classifier: 1.3057 (1.8821)  loss_box_reg: 0.8130 (0.7995)  loss_objectness: 0.0528 (0.3111)  loss_rpn_box_reg: 0.3006 (0.4940)  time: 0.5387  data: 0.0021  max mem: 3529\n",
      "Epoch: [0]  [  150/54500]  eta: 7:46:23  lr: 0.000759  loss: 2.5067 (3.4160)  loss_classifier: 1.2752 (1.8353)  loss_box_reg: 0.8130 (0.7972)  loss_objectness: 0.0546 (0.2944)  loss_rpn_box_reg: 0.3064 (0.4890)  time: 0.5350  data: 0.0020  max mem: 3529\n",
      "Epoch: [0]  [  160/54500]  eta: 7:47:08  lr: 0.000809  loss: 2.4523 (3.3464)  loss_classifier: 1.2569 (1.7920)  loss_box_reg: 0.8357 (0.7945)  loss_objectness: 0.0565 (0.2798)  loss_rpn_box_reg: 0.3848 (0.4801)  time: 0.5252  data: 0.0018  max mem: 3529\n",
      "Epoch: [0]  [  170/54500]  eta: 7:49:05  lr: 0.000859  loss: 2.5209 (3.2948)  loss_classifier: 1.2078 (1.7529)  loss_box_reg: 0.8141 (0.7913)  loss_objectness: 0.0732 (0.2685)  loss_rpn_box_reg: 0.4040 (0.4821)  time: 0.5420  data: 0.0022  max mem: 3529\n",
      "Epoch: [0]  [  180/54500]  eta: 7:49:19  lr: 0.000909  loss: 2.3600 (3.2281)  loss_classifier: 1.1753 (1.7109)  loss_box_reg: 0.7955 (0.7855)  loss_objectness: 0.0737 (0.2578)  loss_rpn_box_reg: 0.3747 (0.4740)  time: 0.5394  data: 0.0023  max mem: 3529\n",
      "Epoch: [0]  [  190/54500]  eta: 7:49:56  lr: 0.000959  loss: 2.2129 (3.1672)  loss_classifier: 1.0925 (1.6732)  loss_box_reg: 0.7793 (0.7818)  loss_objectness: 0.0497 (0.2465)  loss_rpn_box_reg: 0.2685 (0.4656)  time: 0.5288  data: 0.0023  max mem: 3529\n",
      "Epoch: [0]  [  200/54500]  eta: 7:47:45  lr: 0.001009  loss: 2.3192 (3.1295)  loss_classifier: 1.0830 (1.6436)  loss_box_reg: 0.7626 (0.7810)  loss_objectness: 0.0403 (0.2365)  loss_rpn_box_reg: 0.3507 (0.4685)  time: 0.5030  data: 0.0024  max mem: 3529\n",
      "Epoch: [0]  [  210/54500]  eta: 7:47:12  lr: 0.001059  loss: 2.3192 (3.0794)  loss_classifier: 1.0168 (1.6108)  loss_box_reg: 0.7501 (0.7783)  loss_objectness: 0.0343 (0.2272)  loss_rpn_box_reg: 0.4037 (0.4631)  time: 0.4895  data: 0.0024  max mem: 3529\n",
      "Epoch: [0]  [  220/54500]  eta: 7:48:06  lr: 0.001109  loss: 2.1895 (3.0430)  loss_classifier: 1.0079 (1.5817)  loss_box_reg: 0.7425 (0.7759)  loss_objectness: 0.0317 (0.2224)  loss_rpn_box_reg: 0.3832 (0.4631)  time: 0.5231  data: 0.0023  max mem: 3529\n",
      "Epoch: [0]  [  230/54500]  eta: 7:51:16  lr: 0.001159  loss: 2.1711 (2.9993)  loss_classifier: 0.9936 (1.5536)  loss_box_reg: 0.7142 (0.7719)  loss_objectness: 0.0330 (0.2145)  loss_rpn_box_reg: 0.3477 (0.4593)  time: 0.5704  data: 0.0021  max mem: 3530\n",
      "Epoch: [0]  [  240/54500]  eta: 7:50:54  lr: 0.001209  loss: 1.9835 (2.9463)  loss_classifier: 0.9016 (1.5198)  loss_box_reg: 0.7014 (0.7632)  loss_objectness: 0.0434 (0.2080)  loss_rpn_box_reg: 0.3384 (0.4553)  time: 0.5571  data: 0.0021  max mem: 3530\n",
      "Epoch: [0]  [  250/54500]  eta: 7:49:54  lr: 0.001259  loss: 1.9736 (2.9091)  loss_classifier: 0.8895 (1.4951)  loss_box_reg: 0.6985 (0.7591)  loss_objectness: 0.0436 (0.2014)  loss_rpn_box_reg: 0.4120 (0.4534)  time: 0.5044  data: 0.0022  max mem: 3530\n",
      "Epoch: [0]  [  260/54500]  eta: 7:47:39  lr: 0.001309  loss: 1.9581 (2.8706)  loss_classifier: 0.8896 (1.4705)  loss_box_reg: 0.6680 (0.7543)  loss_objectness: 0.0426 (0.1961)  loss_rpn_box_reg: 0.4120 (0.4497)  time: 0.4764  data: 0.0024  max mem: 3530\n",
      "Epoch: [0]  [  270/54500]  eta: 7:45:47  lr: 0.001359  loss: 1.8410 (2.8302)  loss_classifier: 0.8299 (1.4449)  loss_box_reg: 0.6328 (0.7484)  loss_objectness: 0.0430 (0.1904)  loss_rpn_box_reg: 0.3203 (0.4465)  time: 0.4607  data: 0.0022  max mem: 3530\n",
      "Epoch: [0]  [  280/54500]  eta: 7:45:40  lr: 0.001409  loss: 1.8789 (2.7995)  loss_classifier: 0.8105 (1.4242)  loss_box_reg: 0.6328 (0.7451)  loss_objectness: 0.0384 (0.1852)  loss_rpn_box_reg: 0.3522 (0.4450)  time: 0.4891  data: 0.0021  max mem: 3530\n",
      "Epoch: [0]  [  290/54500]  eta: 7:47:03  lr: 0.001459  loss: 1.9425 (2.7670)  loss_classifier: 0.7939 (1.3991)  loss_box_reg: 0.6404 (0.7380)  loss_objectness: 0.0358 (0.1799)  loss_rpn_box_reg: 0.4204 (0.4501)  time: 0.5384  data: 0.0022  max mem: 3530\n",
      "Epoch: [0]  [  300/54500]  eta: 7:48:20  lr: 0.001508  loss: 1.8350 (2.7291)  loss_classifier: 0.7256 (1.3748)  loss_box_reg: 0.5833 (0.7304)  loss_objectness: 0.0285 (0.1753)  loss_rpn_box_reg: 0.3639 (0.4485)  time: 0.5626  data: 0.0022  max mem: 3530\n",
      "Epoch: [0]  [  310/54500]  eta: 7:47:40  lr: 0.001558  loss: 1.8216 (2.7009)  loss_classifier: 0.7818 (1.3555)  loss_box_reg: 0.5833 (0.7257)  loss_objectness: 0.0368 (0.1712)  loss_rpn_box_reg: 0.4136 (0.4486)  time: 0.5308  data: 0.0026  max mem: 3530\n",
      "Epoch: [0]  [  320/54500]  eta: 7:49:12  lr: 0.001608  loss: 1.8004 (2.6709)  loss_classifier: 0.7906 (1.3357)  loss_box_reg: 0.5784 (0.7199)  loss_objectness: 0.0368 (0.1671)  loss_rpn_box_reg: 0.3583 (0.4482)  time: 0.5370  data: 0.0024  max mem: 3530\n",
      "Epoch: [0]  [  330/54500]  eta: 7:49:45  lr: 0.001658  loss: 1.7400 (2.6431)  loss_classifier: 0.7314 (1.3174)  loss_box_reg: 0.5715 (0.7142)  loss_objectness: 0.0296 (0.1630)  loss_rpn_box_reg: 0.3583 (0.4485)  time: 0.5589  data: 0.0022  max mem: 3530\n",
      "Epoch: [0]  [  340/54500]  eta: 7:49:06  lr: 0.001708  loss: 1.7228 (2.6143)  loss_classifier: 0.7276 (1.2994)  loss_box_reg: 0.5405 (0.7085)  loss_objectness: 0.0299 (0.1595)  loss_rpn_box_reg: 0.4128 (0.4469)  time: 0.5210  data: 0.0026  max mem: 3530\n",
      "Epoch: [0]  [  350/54500]  eta: 7:50:25  lr: 0.001758  loss: 1.6746 (2.5851)  loss_classifier: 0.6971 (1.2809)  loss_box_reg: 0.5203 (0.7018)  loss_objectness: 0.0373 (0.1563)  loss_rpn_box_reg: 0.3922 (0.4461)  time: 0.5369  data: 0.0024  max mem: 3530\n",
      "Epoch: [0]  [  360/54500]  eta: 7:53:12  lr: 0.001808  loss: 1.6083 (2.5574)  loss_classifier: 0.6595 (1.2630)  loss_box_reg: 0.4982 (0.6953)  loss_objectness: 0.0362 (0.1532)  loss_rpn_box_reg: 0.3566 (0.4460)  time: 0.6051  data: 0.0023  max mem: 3530\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 6.00 GiB total capacity; 3.26 GiB already allocated; 157.56 MiB free; 4.03 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6c2da2ec76ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# train for one epoch, printing every 10 iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# update the learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\My Documents\\MathExprSolverMx\\MathExprSolverMx\\training\\engine.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 200.00 MiB (GPU 0; 6.00 GiB total capacity; 3.26 GiB already allocated; 157.56 MiB free; 4.03 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# let's train it for 10 epochs\n",
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "savePath = os.path.join(os.getcwd(), 'mathRecognizerMx_2epochwBgrd.pt')\n",
    "torch.save(model.state_dict(), savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
